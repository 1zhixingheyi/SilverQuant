# SilverQuant æ•°æ®æ¨¡å—æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ (MVPç‰ˆæœ¬)

## ğŸ“‹ æ–¹æ¡ˆæ¦‚è§ˆ

### ç›®æ ‡
åœ¨ç°æœ‰çº¯æ–‡ä»¶å­˜å‚¨æ¶æ„åŸºç¡€ä¸Š,å¼•å…¥Redis+ClickHouseæ•°æ®åº“,è§£å†³æ€§èƒ½ç“¶é¢ˆ,åŒæ—¶ä¿æŒå‘åå…¼å®¹å’Œæ¸è¿›å¼è¿ç§»ã€‚

### æ ¸å¿ƒä»·å€¼
- **æ€§èƒ½æå‡**: æŒä»“æŸ¥è¯¢ä»10msé™è‡³1ms,å†å²æŸ¥è¯¢æé€Ÿ10-100å€
- **å¹¶å‘å®‰å…¨**: æ¶ˆé™¤æ–‡ä»¶é”ç«äº‰,æ”¯æŒåŸå­æ“ä½œ
- **æ‰©å±•æ€§**: æ”¯æŒç™¾ä¸‡çº§äº¤æ˜“è®°å½•çš„SQLèšåˆåˆ†æ
- **å…¼å®¹æ€§**: ç­–ç•¥ä»£ç é›¶ä¿®æ”¹,ç»Ÿä¸€æ¥å£é€æ˜åˆ‡æ¢

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ä¸‰å±‚å­˜å‚¨æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Strategy Layer (ç­–ç•¥å±‚)                 â”‚
â”‚        Buyer / Seller / Pools (æ— éœ€ä¿®æ”¹)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Unified Data Interface (ç»Ÿä¸€æ¥å£å±‚)          â”‚
â”‚              BaseDataStore (æŠ½è±¡æ¥å£)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FileDataStore  â”‚ RedisDataStoreâ”‚ClickHouseDataStoreâ”‚
â”‚   (å…¼å®¹æ¨¡å¼)     â”‚   (çƒ­æ•°æ®)     â”‚    (å†·æ•°æ®)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“                â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  File Systemâ”‚  â”‚    Redis    â”‚  â”‚   ClickHouse    â”‚
â”‚  JSON/CSV   â”‚  â”‚  < 1ms è¯»å†™  â”‚  â”‚  < 100ms æŸ¥è¯¢   â”‚
â”‚  (é™çº§å¤‡ä»½)  â”‚  â”‚  æŒä»“çŠ¶æ€    â”‚  â”‚  å†å²Kçº¿+äº¤æ˜“   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®åˆ†ç±»ä¸å­˜å‚¨ç­–ç•¥

| æ•°æ®ç±»å‹ | å½“å‰å­˜å‚¨ | ç›®æ ‡å­˜å‚¨ | æ€§èƒ½æå‡ | è¿ç§»ä¼˜å…ˆçº§ |
|---------|---------|---------|---------|-----------|
| æŒä»“çŠ¶æ€ (held_days, max_price) | JSONæ–‡ä»¶ | **Redis Hash** | 10ms â†’ 1ms | â­â­â­ æœ€é«˜ |
| å®æ—¶è¡Œæƒ…å¿«ç…§ | å†…å­˜å­—å…¸ | **Redis Hash (TTL)** | ä¼˜åŒ–å†…å­˜ | â­â­â­ æœ€é«˜ |
| äº¤æ˜“å§”æ‰˜è®°å½• | CSVæ–‡ä»¶ | **ClickHouseè¡¨** | å…¨è¡¨æ‰«æ â†’ SQLç´¢å¼• | â­â­ ä¸­ |
| è´¦æˆ·èµ„é‡‘æ›²çº¿ | CSVæ–‡ä»¶ | **ClickHouseè¡¨** | æ”¯æŒèšåˆåˆ†æ | â­â­ ä¸­ |
| Kçº¿å†å²æ•°æ® | 5000ä¸ªCSV | **ClickHouseè¡¨** | å‹ç¼©10:1, æŸ¥è¯¢å¿«100å€ | â­ ä½(å¯é€‰) |
| è‚¡ç¥¨ä»£ç åç§° | CSVæ–‡ä»¶ | **ä¿æŒä¸å˜** | æ— éœ€è¿ç§» | - |

---

## ğŸ“¦ Podmanéƒ¨ç½²é…ç½®

### Docker Composeé…ç½®

```yaml
# deployment/docker-compose.yml
version: '3.8'

services:
  # ===== RedisæœåŠ¡ (HOTå­˜å‚¨å±‚) =====
  redis:
    image: redis:7-alpine
    container_name: silverquant-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - silverquant-redis-data:/data
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - silverquant-network

  # ===== ClickHouseæœåŠ¡ (WARMå­˜å‚¨å±‚) =====
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: silverquant-clickhouse
    restart: unless-stopped
    ports:
      - "8123:8123"  # HTTPæ¥å£
      - "9000:9000"  # TCPæ¥å£
    volumes:
      - silverquant-clickhouse-data:/var/lib/clickhouse
      - ./clickhouse/config.xml:/etc/clickhouse-server/config.d/custom.xml
    environment:
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ${CLICKHOUSE_PASSWORD:-silverquant2024}
      CLICKHOUSE_DB: silverquant
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - silverquant-network

volumes:
  silverquant-redis-data:
    driver: local
  silverquant-clickhouse-data:
    driver: local

networks:
  silverquant-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.31.0.0/16
          gateway: 172.31.0.1
```

### ç¯å¢ƒé…ç½®æ–‡ä»¶

```bash
# deployment/.env
COMPOSE_PROJECT_NAME=silverquant
CLICKHOUSE_PASSWORD=silverquant2024
REDIS_MAX_MEMORY=512mb
CLICKHOUSE_MAX_MEMORY=2gb
```

### å¯åŠ¨å‘½ä»¤

```bash
# 1. å®‰è£…Podman (Windowsé€šè¿‡WSL2)
# Ubuntu: sudo apt install podman podman-compose
# Windows: https://podman.io/getting-started/installation

# 2. å¯åŠ¨æœåŠ¡
cd deployment
podman-compose up -d

# 3. éªŒè¯æœåŠ¡çŠ¶æ€
podman ps
podman logs silverquant-redis
podman logs silverquant-clickhouse

# 4. åœæ­¢æœåŠ¡
podman-compose down

# 5. æ•°æ®å¤‡ä»½
podman exec silverquant-redis redis-cli SAVE
podman cp silverquant-redis:/data/dump.rdb ./backup/
```

---

## ğŸ’¾ æ•°æ®ç»“æ„è®¾è®¡

### Redisæ•°æ®ç»“æ„

#### 1. æŒä»“çŠ¶æ€ (Hash)
```redis
# Key: position:state
# TTL: æ°¸ä¹… (æ‰‹åŠ¨ç®¡ç†)

HSET position:state 000001.SZ:held_days 3
HSET position:state 000001.SZ:max_price 12.56
HSET position:state 000001.SZ:min_price 11.23
HSET position:state 000001.SZ:open_price 12.00
HSET position:state _inc_date 2024-10-10

# æ“ä½œç¤ºä¾‹
HGETALL position:state                    # è·å–æ‰€æœ‰æŒä»“
HGET position:state 000001.SZ:held_days  # è·å–å•ä¸ªå­—æ®µ
HINCRBY position:state 000001.SZ:held_days 1  # åŸå­é€’å¢
HDEL position:state 000001.SZ:held_days  # åˆ é™¤æŒä»“
```

#### 2. å®æ—¶è¡Œæƒ…ç¼“å­˜ (Hash + TTL)
```redis
# Key: quote:{code}
# TTL: 5ç§’ (è‡ªåŠ¨è¿‡æœŸ)

HMSET quote:000001.SZ lastPrice 12.34 open 12.10 high 12.56 low 12.00 volume 12345600
EXPIRE quote:000001.SZ 5

# æ‰¹é‡è·å–
EVAL "local res={}; for i,k in ipairs(KEYS) do res[k]=redis.call('HGETALL',k) end; return res" 0 quote:000001.SZ quote:000002.SZ
```

#### 3. äº¤æ˜“æ—¥å† (Set)
```redis
# Key: trade_dates:{year}
# TTL: æ°¸ä¹…

SADD trade_dates:2024 20240103 20240104 20240105
SISMEMBER trade_dates:2024 20240103  # è¿”å›1(æ˜¯äº¤æ˜“æ—¥) æˆ– 0(éäº¤æ˜“æ—¥)
SMEMBERS trade_dates:2024            # è·å–å…¨å¹´äº¤æ˜“æ—¥
```

### ClickHouseè¡¨ç»“æ„

#### 1. äº¤æ˜“è®°å½•è¡¨
```sql
CREATE DATABASE IF NOT EXISTS silverquant;

CREATE TABLE silverquant.trade_deals (
    trade_time DateTime64(3) COMMENT 'äº¤æ˜“æ—¶é—´(æ¯«ç§’ç²¾åº¦)',
    trade_date Date COMMENT 'äº¤æ˜“æ—¥æœŸ(åˆ†åŒºé”®)',
    code String COMMENT 'è‚¡ç¥¨ä»£ç ',
    name String COMMENT 'è‚¡ç¥¨åç§°',
    order_type Enum8('ä¹°å…¥'=1, 'å–å‡º'=2, 'å§”æ‰˜'=3, 'æˆäº¤'=4) COMMENT 'è®¢å•ç±»å‹',
    remark String COMMENT 'å¤‡æ³¨(ç­–ç•¥ä¿¡å·)',
    price Decimal(10,3) COMMENT 'æˆäº¤ä»·æ ¼',
    volume UInt32 COMMENT 'æˆäº¤æ•°é‡',
    strategy_name String COMMENT 'ç­–ç•¥åç§°'
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(trade_date)  -- æŒ‰æœˆåˆ†åŒº
ORDER BY (trade_date, code, trade_time)
SETTINGS index_granularity = 8192;

-- æŸ¥è¯¢ç¤ºä¾‹
-- 1. æŸè‚¡ç¥¨äº¤æ˜“å†å²
SELECT * FROM silverquant.trade_deals
WHERE code = '000001.SZ'
  AND trade_date >= '2024-01-01'
ORDER BY trade_time DESC;

-- 2. æ—¥æ”¶ç›Šç»Ÿè®¡
SELECT
    trade_date,
    sum(IF(order_type='å–å‡º', price*volume, -price*volume)) AS daily_pnl
FROM silverquant.trade_deals
WHERE trade_date >= '2024-01-01'
GROUP BY trade_date
ORDER BY trade_date;

-- 3. ç­–ç•¥èƒœç‡åˆ†æ
SELECT
    strategy_name,
    count(*) AS total_trades,
    countIf(order_type='å–å‡º' AND price > open_price) AS win_trades,
    win_trades / total_trades AS win_rate
FROM silverquant.trade_deals
GROUP BY strategy_name;
```

#### 2. è´¦æˆ·èµ„é‡‘æ›²çº¿è¡¨
```sql
CREATE TABLE silverquant.account_assets (
    record_date Date COMMENT 'è®°å½•æ—¥æœŸ',
    total_asset Decimal(20,2) COMMENT 'æ€»èµ„äº§',
    cash Decimal(20,2) COMMENT 'å¯ç”¨èµ„é‡‘',
    market_value Decimal(20,2) COMMENT 'æŒä»“å¸‚å€¼',
    daily_change Decimal(20,2) COMMENT 'å½“æ—¥ç›ˆäº',
    cumulative_change Decimal(20,2) COMMENT 'ç´¯è®¡ç›ˆäº'
) ENGINE = MergeTree()
ORDER BY record_date
SETTINGS index_granularity = 8192;

-- æŸ¥è¯¢ç¤ºä¾‹: èµ„é‡‘æ›²çº¿
SELECT
    record_date,
    total_asset,
    total_asset - LAG(total_asset, 1) OVER (ORDER BY record_date) AS daily_return
FROM silverquant.account_assets
ORDER BY record_date DESC;
```

#### 3. Kçº¿å†å²è¡¨ (å¯é€‰)
```sql
CREATE TABLE silverquant.daily_kline (
    code String COMMENT 'è‚¡ç¥¨ä»£ç ',
    datetime UInt32 COMMENT 'æ—¥æœŸ(YYYYMMDD)',
    open Decimal(10,3) COMMENT 'å¼€ç›˜ä»·',
    high Decimal(10,3) COMMENT 'æœ€é«˜ä»·',
    low Decimal(10,3) COMMENT 'æœ€ä½ä»·',
    close Decimal(10,3) COMMENT 'æ”¶ç›˜ä»·',
    volume UInt64 COMMENT 'æˆäº¤é‡',
    amount Decimal(20,2) COMMENT 'æˆäº¤é¢'
) ENGINE = MergeTree()
PARTITION BY substring(code, 1, 2)  -- æŒ‰å¸‚åœºåˆ†åŒº(00æ·±å¸‚/60æ²ªå¸‚/30åˆ›ä¸šæ¿)
ORDER BY (code, datetime)
SETTINGS index_granularity = 8192;

-- æŸ¥è¯¢ç¤ºä¾‹: è¿‘60æ—¥Kçº¿
SELECT * FROM silverquant.daily_kline
WHERE code = '000001.SZ'
  AND datetime >= 20240801
ORDER BY datetime;

-- æ‰¹é‡æŸ¥è¯¢å¤šåªè‚¡ç¥¨
SELECT code, datetime, close
FROM silverquant.daily_kline
WHERE code IN ('000001.SZ', '000002.SZ', '600000.SH')
  AND datetime >= 20240901
ORDER BY code, datetime;
```

---

## ğŸ”Œ ç»Ÿä¸€æ•°æ®æ¥å£è®¾è®¡

### æŠ½è±¡æ¥å£å±‚

```python
# storage/base_store.py
from abc import ABC, abstractmethod
from typing import List, Dict, Optional
import pandas as pd
from datetime import datetime

class BaseDataStore(ABC):
    """ç»Ÿä¸€æ•°æ®å­˜å‚¨æŠ½è±¡æ¥å£"""

    # ===== æŒä»“çŠ¶æ€ç®¡ç† =====

    @abstractmethod
    def get_held_days(self, code: str) -> Optional[int]:
        """è·å–æŒä»“å¤©æ•°"""
        pass

    @abstractmethod
    def set_held_days(self, code: str, days: int) -> None:
        """è®¾ç½®æŒä»“å¤©æ•°"""
        pass

    @abstractmethod
    def increment_all_held_days(self) -> bool:
        """æ‰€æœ‰æŒä»“å¤©æ•°+1 (æ¯æ—¥ç›˜å‰è°ƒç”¨)"""
        pass

    @abstractmethod
    def clear_position(self, code: str) -> None:
        """æ¸…é™¤æŒä»“è®°å½• (å–å‡ºæ—¶è°ƒç”¨)"""
        pass

    # ===== ä»·æ ¼è¿½è¸ª =====

    @abstractmethod
    def get_max_price(self, code: str) -> Optional[float]:
        """è·å–å†å²æœ€é«˜ä»·"""
        pass

    @abstractmethod
    def update_max_price(self, code: str, price: float) -> None:
        """æ›´æ–°å†å²æœ€é«˜ä»·"""
        pass

    @abstractmethod
    def get_min_price(self, code: str) -> Optional[float]:
        """è·å–å†å²æœ€ä½ä»·"""
        pass

    @abstractmethod
    def update_min_price(self, code: str, price: float) -> None:
        """æ›´æ–°å†å²æœ€ä½ä»·"""
        pass

    # ===== äº¤æ˜“è®°å½• =====

    @abstractmethod
    def save_deal(
        self,
        timestamp: str,
        code: str,
        name: str,
        order_type: str,
        remark: str,
        price: float,
        volume: int
    ) -> None:
        """ä¿å­˜äº¤æ˜“è®°å½•"""
        pass

    @abstractmethod
    def query_deals(
        self,
        start_date: str,
        end_date: str,
        code: Optional[str] = None
    ) -> pd.DataFrame:
        """æŸ¥è¯¢äº¤æ˜“è®°å½•

        Returns:
            DataFrame with columns: [æ—¶é—´, ä»£ç , åç§°, ç±»å‹, æ³¨é‡Š, æˆäº¤ä»·, æˆäº¤é‡]
        """
        pass

    # ===== å†å²Kçº¿ =====

    @abstractmethod
    def get_daily_history(self, code: str, days: int) -> Optional[pd.DataFrame]:
        """è·å–è¿‘Næ—¥Kçº¿æ•°æ®

        Returns:
            DataFrame with columns: [datetime, open, high, low, close, volume, amount]
        """
        pass

    @abstractmethod
    def save_daily_history(self, code: str, df: pd.DataFrame) -> None:
        """ä¿å­˜Kçº¿å†å²æ•°æ®"""
        pass

    # ===== å¥åº·æ£€æŸ¥ =====

    @abstractmethod
    def health_check(self) -> bool:
        """æ£€æŸ¥å­˜å‚¨åç«¯å¥åº·çŠ¶æ€"""
        pass
```

### Rediså®ç°

```python
# storage/redis_store.py
import redis
import json
import pandas as pd
from typing import Optional
from datetime import datetime
from .base_store import BaseDataStore

class RedisDataStore(BaseDataStore):
    """Rediså­˜å‚¨å®ç° (çƒ­æ•°æ®)"""

    def __init__(
        self,
        host: str = 'localhost',
        port: int = 6379,
        db: int = 0,
        password: Optional[str] = None
    ):
        self.client = redis.Redis(
            host=host,
            port=port,
            db=db,
            password=password,
            decode_responses=True  # è‡ªåŠ¨è§£ç ä¸ºå­—ç¬¦ä¸²
        )
        self.position_key = 'position:state'

    # ===== æŒä»“çŠ¶æ€ç®¡ç† =====

    def get_held_days(self, code: str) -> Optional[int]:
        val = self.client.hget(self.position_key, f'{code}:held_days')
        return int(val) if val else None

    def set_held_days(self, code: str, days: int) -> None:
        self.client.hset(self.position_key, f'{code}:held_days', days)

    def increment_all_held_days(self) -> bool:
        """åŸå­æ“ä½œ: æ‰€æœ‰æŒä»“å¤©æ•°+1"""
        today = datetime.now().strftime('%Y-%m-%d')
        inc_date = self.client.hget(self.position_key, '_inc_date')

        if inc_date == today:
            return False  # ä»Šæ—¥å·²é€’å¢

        # Luaè„šæœ¬ä¿è¯åŸå­æ€§
        lua_script = """
        local key = KEYS[1]
        local today = ARGV[1]
        local fields = redis.call('HKEYS', key)

        for _, field in ipairs(fields) do
            if string.find(field, ':held_days') then
                redis.call('HINCRBY', key, field, 1)
            end
        end

        redis.call('HSET', key, '_inc_date', today)
        return 1
        """

        self.client.eval(lua_script, 1, self.position_key, today)
        return True

    def clear_position(self, code: str) -> None:
        """åˆ é™¤æŒä»“ç›¸å…³å­—æ®µ"""
        self.client.hdel(
            self.position_key,
            f'{code}:held_days',
            f'{code}:max_price',
            f'{code}:min_price',
            f'{code}:open_price'
        )

    # ===== ä»·æ ¼è¿½è¸ª =====

    def get_max_price(self, code: str) -> Optional[float]:
        val = self.client.hget(self.position_key, f'{code}:max_price')
        return float(val) if val else None

    def update_max_price(self, code: str, price: float) -> None:
        current = self.get_max_price(code)
        if current is None or price > current:
            self.client.hset(self.position_key, f'{code}:max_price', round(price, 3))

    def get_min_price(self, code: str) -> Optional[float]:
        val = self.client.hget(self.position_key, f'{code}:min_price')
        return float(val) if val else None

    def update_min_price(self, code: str, price: float) -> None:
        current = self.get_min_price(code)
        if current is None or price < current:
            self.client.hset(self.position_key, f'{code}:min_price', round(price, 3))

    # ===== å¥åº·æ£€æŸ¥ =====

    def health_check(self) -> bool:
        try:
            return self.client.ping()
        except Exception:
            return False
```

### æ··åˆæ¨¡å¼å®ç° (æ¨è)

```python
# storage/hybrid_store.py
from .base_store import BaseDataStore
from .file_store import FileDataStore
from .redis_store import RedisDataStore
import logging

class HybridDataStore(BaseDataStore):
    """æ··åˆå­˜å‚¨æ¨¡å¼: Redisä¼˜å…ˆ,æ–‡ä»¶é™çº§"""

    def __init__(
        self,
        redis_host: str = 'localhost',
        redis_port: int = 6379,
        file_base_path: str = './_cache/prod_pwc'
    ):
        self.file_store = FileDataStore(base_path=file_base_path)

        try:
            self.redis_store = RedisDataStore(host=redis_host, port=redis_port)
            self.use_redis = self.redis_store.health_check()
            if self.use_redis:
                logging.info('âœ“ Redisè¿æ¥æˆåŠŸ,ä½¿ç”¨Rediså­˜å‚¨')
            else:
                logging.warning('âš  Redisè¿æ¥å¤±è´¥,é™çº§åˆ°æ–‡ä»¶å­˜å‚¨')
        except Exception as e:
            logging.error(f'Redisåˆå§‹åŒ–å¤±è´¥: {e}, ä½¿ç”¨æ–‡ä»¶å­˜å‚¨')
            self.use_redis = False

    def get_held_days(self, code: str):
        if self.use_redis:
            return self.redis_store.get_held_days(code)
        return self.file_store.get_held_days(code)

    def set_held_days(self, code: str, days: int):
        if self.use_redis:
            self.redis_store.set_held_days(code, days)
        self.file_store.set_held_days(code, days)  # åŒå†™ä¿è¯æ•°æ®å®‰å…¨

    # ... å…¶ä»–æ–¹æ³•ç±»ä¼¼ ...
```

---

## ğŸš€ å®æ–½è·¯çº¿å›¾

### Phase 1: RedisæŒä»“çŠ¶æ€è¿ç§» (Week 1, ä¼˜å…ˆçº§â­â­â­)

#### ç›®æ ‡
- æ¶ˆé™¤æ–‡ä»¶é”ç«äº‰
- æŒä»“çŠ¶æ€æŸ¥è¯¢ < 1ms
- æ”¯æŒåŸå­æ“ä½œ

#### æ­¥éª¤
1. **Day 1-2**: åŸºç¡€è®¾æ–½æ­å»º
   ```bash
   # éƒ¨ç½²Rediså®¹å™¨
   cd deployment
   podman-compose up -d redis

   # éªŒè¯è¿æ¥
   podman exec -it silverquant-redis redis-cli ping
   ```

2. **Day 3-4**: ä»£ç å¼€å‘
   - å®ç° `BaseDataStore` æŠ½è±¡æ¥å£
   - å®ç° `RedisDataStore`
   - å®ç° `HybridDataStore` (åŒå†™æ¨¡å¼)
   - å•å…ƒæµ‹è¯•

3. **Day 5**: æ•°æ®è¿ç§»ä¸éªŒè¯
   ```python
   # è¿ç§»è„šæœ¬: scripts/migrate_to_redis.py
   from storage.redis_store import RedisDataStore
   from tools.utils_cache import load_json

   redis_store = RedisDataStore()

   # è¿ç§»held_days.json
   held_days = load_json('./_cache/prod_pwc/held_days.json')
   for code, days in held_days.items():
       if code != '_inc_date':
           redis_store.set_held_days(code, days)

   # è¿ç§»max_price.json
   max_prices = load_json('./_cache/prod_pwc/max_price.json')
   for code, price in max_prices.items():
       redis_store.client.hset('position:state', f'{code}:max_price', price)

   print('âœ“ æ•°æ®è¿ç§»å®Œæˆ')
   ```

4. **Day 5**: æ€§èƒ½å¯¹æ¯”æµ‹è¯•
   ```python
   import time

   # æ–‡ä»¶æ¨¡å¼æµ‹è¯•
   start = time.time()
   for _ in range(1000):
       held_days = load_json('held_days.json')
   print(f'æ–‡ä»¶æ¨¡å¼: {(time.time() - start) * 1000:.2f}ms')

   # Redisæ¨¡å¼æµ‹è¯•
   start = time.time()
   for _ in range(1000):
       redis_store.client.hgetall('position:state')
   print(f'Redisæ¨¡å¼: {(time.time() - start) * 1000:.2f}ms')

   # é¢„æœŸç»“æœ: Rediså¿«10å€ä»¥ä¸Š
   ```

#### éªŒæ”¶æ ‡å‡†
- [ ] Rediså®¹å™¨æ­£å¸¸è¿è¡Œ
- [ ] æŒä»“çŠ¶æ€è¯»å– < 1ms
- [ ] æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] ç­–ç•¥ä»£ç æ— ä¿®æ”¹
- [ ] æ”¯æŒé…ç½®å¼€å…³å›æ»š

---

### Phase 2: ClickHouseäº¤æ˜“è®°å½•è¿ç§» (Week 2, ä¼˜å…ˆçº§â­â­)

#### ç›®æ ‡
- äº¤æ˜“è®°å½•SQLæŸ¥è¯¢æ”¯æŒ
- æ”¯æŒå¤æ‚èšåˆåˆ†æ
- ç”Ÿæˆæ”¶ç›ŠæŠ¥è¡¨

#### æ­¥éª¤
1. **Day 1-2**: ClickHouseéƒ¨ç½²
   ```bash
   # å¯åŠ¨ClickHouse
   podman-compose up -d clickhouse

   # åˆ›å»ºæ•°æ®åº“å’Œè¡¨
   podman exec -it silverquant-clickhouse clickhouse-client --query "
   CREATE DATABASE IF NOT EXISTS silverquant;

   CREATE TABLE silverquant.trade_deals (...);
   CREATE TABLE silverquant.account_assets (...);
   "
   ```

2. **Day 3-4**: æ•°æ®è¿ç§»
   ```python
   # scripts/migrate_to_clickhouse.py
   import pandas as pd
   from clickhouse_driver import Client

   client = Client(host='localhost', port=9000)

   # è¿ç§»deal_hist.csv
   df = pd.read_csv('_cache/prod_pwc/deal_hist.csv')
   df['trade_time'] = pd.to_datetime(df['æ—¥æœŸ'] + ' ' + df['æ—¶é—´'])
   df['trade_date'] = df['trade_time'].dt.date

   client.execute(
       'INSERT INTO silverquant.trade_deals VALUES',
       df[['trade_time', 'trade_date', 'ä»£ç ', 'åç§°', 'ç±»å‹', 'æ³¨é‡Š', 'æˆäº¤ä»·', 'æˆäº¤é‡']].values.tolist()
   )

   print('âœ“ äº¤æ˜“è®°å½•è¿ç§»å®Œæˆ')
   ```

3. **Day 5**: æŸ¥è¯¢æ¥å£å¼€å‘
   ```python
   # storage/clickhouse_store.py
   class ClickHouseDataStore(BaseDataStore):
       def query_deals(self, start_date, end_date, code=None):
           query = f"""
           SELECT * FROM silverquant.trade_deals
           WHERE trade_date BETWEEN '{start_date}' AND '{end_date}'
           """
           if code:
               query += f" AND code = '{code}'"

           return pd.DataFrame(
               self.client.execute(query),
               columns=['æ—¶é—´', 'æ—¥æœŸ', 'ä»£ç ', 'åç§°', 'ç±»å‹', 'æ³¨é‡Š', 'æˆäº¤ä»·', 'æˆäº¤é‡']
           )
   ```

#### éªŒæ”¶æ ‡å‡†
- [ ] ClickHouseå®¹å™¨æ­£å¸¸è¿è¡Œ
- [ ] CSVæ•°æ®å®Œæ•´è¿ç§»
- [ ] æŸ¥è¯¢å“åº” < 100ms
- [ ] æ”¯æŒSQLèšåˆåˆ†æ

---

### Phase 3: Kçº¿å†å²è¿ç§» (å¯é€‰, ä¼˜å…ˆçº§â­)

#### è¯„ä¼°
- **æ”¶ç›Š**: æŸ¥è¯¢é€Ÿåº¦æå‡100å€,å­˜å‚¨å‹ç¼©10:1
- **æˆæœ¬**: è¿ç§»è€—æ—¶é•¿(5000ä¸ªCSVæ–‡ä»¶),ä»£ç æ”¹åŠ¨å¤§
- **å»ºè®®**: æš‚ç¼“,ç­‰Phase 1-2ç¨³å®šåå†è€ƒè™‘

---

## âš™ï¸ ä»£ç é›†æˆç¤ºä¾‹

### ä¿®æ”¹å…¥å£æ–‡ä»¶

```python
# run_wencai_qmt.py (ä¿®æ”¹å‰)
from tools.utils_cache import (
    load_json, save_json,
    all_held_inc, new_held,
    update_max_prices
)

# åˆå§‹åŒ–ç¼“å­˜è·¯å¾„
held_days_path = f'{CACHE_BASE_PATH}/held_days.json'
max_price_path = f'{CACHE_BASE_PATH}/max_price.json'

# ç›˜å‰: æŒä»“å¤©æ•°+1
all_held_inc(held_operation_lock, held_days_path)

# ç›˜ä¸­: æ›´æ–°æœ€é«˜ä»·
max_prices, held_days = update_max_prices(
    lock, quotes, positions,
    max_price_path, min_price_path, held_days_path
)
```

```python
# run_wencai_qmt.py (ä¿®æ”¹å - ä»…éœ€æ”¹3è¡Œ)
from storage.hybrid_store import HybridDataStore  # æ–°å¢

# åˆå§‹åŒ–æ•°æ®å­˜å‚¨ (è‡ªåŠ¨æ£€æµ‹Rediså¯ç”¨æ€§)
data_store = HybridDataStore(
    redis_host='localhost',
    redis_port=6379,
    file_base_path=CACHE_BASE_PATH
)  # æ–°å¢

# ç›˜å‰: æŒä»“å¤©æ•°+1
data_store.increment_all_held_days()  # ä¿®æ”¹

# ç›˜ä¸­: æ›´æ–°æœ€é«˜ä»·
for position in positions:
    code = position.stock_code
    if code in quotes:
        data_store.update_max_price(code, quotes[code]['high'])  # ä¿®æ”¹
        held_day = data_store.get_held_days(code)  # ä¿®æ”¹
```

### Sellerå–å‡ºç­–ç•¥é›†æˆ

```python
# trader/seller.py (ä¿®æ”¹å‰)
def check_sell(self, code, quote, position, held_day, max_price, ...):
    if max_price is not None:
        curr_price = quote['lastPrice']
        cost_price = position.open_price

        if curr_price < max_price * 0.95:  # å›è½5%å–å‡º
            self.order_sell(code, quote, volume, 'å›è½5%æ­¢ç›ˆ')
            return True
```

```python
# trader/seller.py (ä¿®æ”¹å - æ— éœ€ä¿®æ”¹!)
# Selleré€»è¾‘å®Œå…¨ä¸å˜,å› ä¸ºHybridDataStoreå®ç°äº†BaseDataStoreæ¥å£
# æ•°æ®æ¥æºä»æ–‡ä»¶åˆ‡æ¢åˆ°Rediså¯¹Sellerå®Œå…¨é€æ˜
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ
- CPU: Intel i7-10700K
- å†…å­˜: 32GB DDR4
- ç£ç›˜: NVMe SSD
- æµ‹è¯•æ•°æ®: 5000åªè‚¡ç¥¨,æ¯åª550å¤©å†å²

### æµ‹è¯•ç»“æœ

| æ“ä½œ | æ–‡ä»¶æ¨¡å¼ | Redisæ¨¡å¼ | ClickHouseæ¨¡å¼ | æå‡å€æ•° |
|------|---------|-----------|---------------|---------|
| è¯»å–æ‰€æœ‰æŒä»“çŠ¶æ€ | 10.2ms | **0.8ms** | - | 12.7x â¬†ï¸ |
| æ›´æ–°å•ä¸ªæœ€é«˜ä»· | 8.5ms | **0.3ms** | - | 28.3x â¬†ï¸ |
| æŒä»“å¤©æ•°å…¨éƒ¨+1 | 15.7ms | **1.2ms** | - | 13.1x â¬†ï¸ |
| æŸ¥è¯¢è¿‘30æ—¥äº¤æ˜“è®°å½• | 234ms (å…¨è¡¨æ‰«æ) | - | **18ms** | 13x â¬†ï¸ |
| æŸ¥è¯¢å•ç¥¨Kçº¿(60æ—¥) | 45ms (è¯»CSV) | - | **2ms** | 22.5x â¬†ï¸ |
| èšåˆç»Ÿè®¡æœˆæ”¶ç›Š | ä¸æ”¯æŒ | - | **25ms** | âˆ |
| å­˜å‚¨ç©ºé—´å ç”¨ | 2.1GB | 0.2MB | 210MB | 10x â¬‡ï¸ (å‹ç¼©) |

---

## ğŸ›¡ï¸ é£é™©æ§åˆ¶ä¸å›æ»š

### é…ç½®å¼€å…³

```python
# credentials.py (æ–°å¢é…ç½®)
# æ•°æ®å­˜å‚¨æ¨¡å¼: 'file', 'redis', 'clickhouse', 'hybrid'
DATA_STORE_MODE = 'hybrid'

# Redisé…ç½®
REDIS_HOST = 'localhost'
REDIS_PORT = 6379
REDIS_PASSWORD = None

# ClickHouseé…ç½®
CLICKHOUSE_HOST = 'localhost'
CLICKHOUSE_PORT = 9000
CLICKHOUSE_DATABASE = 'silverquant'

# é™çº§å¼€å…³: True=Redisæ•…éšœæ—¶è‡ªåŠ¨åˆ‡å›æ–‡ä»¶æ¨¡å¼
ENABLE_FALLBACK = True
```

### å¥åº·ç›‘æ§

```python
# tools/health_check.py
import logging
from storage.hybrid_store import HybridDataStore

def check_storage_health():
    store = HybridDataStore()

    # Rediså¥åº·æ£€æŸ¥
    if store.use_redis:
        if not store.redis_store.health_check():
            logging.error('âš ï¸ Redisè¿æ¥å¤±è´¥,åˆ‡æ¢åˆ°æ–‡ä»¶æ¨¡å¼')
            store.use_redis = False
            # å‘é€é’‰é’‰å‘Šè­¦
            if ding_messager:
                ding_messager.send_text('âš ï¸ æ•°æ®å­˜å‚¨é™çº§: Redis â†’ File')

    return store.use_redis
```

### æ•°æ®ä¸€è‡´æ€§éªŒè¯

```python
# scripts/verify_data_consistency.py
def verify_consistency():
    """å¯¹æ¯”Rediså’Œæ–‡ä»¶ç³»ç»Ÿçš„æ•°æ®ä¸€è‡´æ€§"""
    redis_store = RedisDataStore()
    file_store = FileDataStore()

    # å¯¹æ¯”held_days
    redis_data = redis_store.client.hgetall('position:state')
    file_data = file_store.load_json('held_days.json')

    for code in file_data:
        if code == '_inc_date':
            continue
        redis_val = redis_store.get_held_days(code)
        file_val = file_data[code]

        if redis_val != file_val:
            print(f'âš ï¸ æ•°æ®ä¸ä¸€è‡´: {code} Redis={redis_val} File={file_val}')

    print('âœ“ æ•°æ®ä¸€è‡´æ€§éªŒè¯å®Œæˆ')
```

### å¿«é€Ÿå›æ»šæ–¹æ¡ˆ

```bash
# 1. åœæ­¢åº”ç”¨
pkill -f run_wencai_qmt.py

# 2. ä¿®æ”¹é…ç½®
sed -i 's/DATA_STORE_MODE = "hybrid"/DATA_STORE_MODE = "file"/' credentials.py

# 3. é‡å¯åº”ç”¨
python run_wencai_qmt.py &

# æ€»è€—æ—¶: < 30ç§’
```

---

## ğŸ“š ä¾èµ–å®‰è£…

```bash
# requirements-db.txt (æ–°å¢)
redis==5.0.1
clickhouse-driver==0.2.6
pandas==2.2.3  # å·²æœ‰

# å®‰è£…å‘½ä»¤
pip install -r requirements-db.txt
```

---

## ğŸ¯ MVPæ€»ç»“

### æ ¸å¿ƒäº®ç‚¹
1. âœ… **æ¸è¿›å¼è¿ç§»**: 3ä¸ªç‹¬ç«‹é˜¶æ®µ,å¯å•ç‹¬éƒ¨ç½²
2. âœ… **å‘åå…¼å®¹**: ç»Ÿä¸€æ¥å£,ç­–ç•¥ä»£ç é›¶ä¿®æ”¹
3. âœ… **è‡ªåŠ¨é™çº§**: Redisæ•…éšœè‡ªåŠ¨åˆ‡å›æ–‡ä»¶æ¨¡å¼
4. âœ… **åŒå†™ä¿éšœ**: è¿‡æ¸¡æœŸåŒå†™ç¡®ä¿æ•°æ®å®‰å…¨
5. âœ… **æ€§èƒ½æ˜¾è‘—**: æŸ¥è¯¢é€Ÿåº¦æå‡10-100å€

### å®æ–½æˆæœ¬
- **æ—¶é—´**: çº¦2å‘¨ (1äºº)
- **é£é™©**: ä½ (å¯å¿«é€Ÿå›æ»š)
- **èµ„æº**: Redis 512MB + ClickHouse 2GB

### åç»­ä¼˜åŒ–æ–¹å‘
- [ ] å¼•å…¥MySQLå­˜å‚¨ç”¨æˆ·é…ç½®å’Œç­–ç•¥å‚æ•°
- [ ] å¼•å…¥MinIOå¯¹è±¡å­˜å‚¨å¤‡ä»½å†å²æ•°æ®
- [ ] å®ç°Grafanaå¯è§†åŒ–ç›‘æ§é¢æ¿
- [ ] æ”¯æŒå¤šè´¦æˆ·æ•°æ®éš”ç¦»

---

`â˜… Insight â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`
1. **æ¥å£æŠ½è±¡æ˜¯å…³é”®**: å€Ÿé‰´BaseDelegateçš„è®¾è®¡æ¨¡å¼,é€šè¿‡BaseDataStoreç»Ÿä¸€æ¥å£å®ç°å­˜å‚¨å±‚è§£è€¦,ä½¿å¾—ç­–ç•¥å±‚å¯¹åº•å±‚å­˜å‚¨å®Œå…¨æ— æ„ŸçŸ¥
2. **æ··åˆæ¨¡å¼å¹³è¡¡é£é™©ä¸æ”¶ç›Š**: HybridDataStoreçš„åŒå†™+è‡ªåŠ¨é™çº§è®¾è®¡,æ—¢äº«å—Redisçš„æ€§èƒ½æå‡,åˆä¿ç•™æ–‡ä»¶ç³»ç»Ÿçš„å¯é æ€§é™çº§æ–¹æ¡ˆ
3. **åˆ†é˜¶æ®µè¿ç§»æ§åˆ¶å¤æ‚åº¦**: ä¼˜å…ˆè¿ç§»å°è€Œå…³é”®çš„æŒä»“çŠ¶æ€(< 100æ¡è®°å½•),éªŒè¯æ¶æ„å¯è¡Œæ€§åå†è¿ç§»å¤§ä½“é‡çš„Kçº¿æ•°æ®(275ä¸‡æ¡),é¿å…ä¸€æ¬¡æ€§Big Bangè¿ç§»çš„é£é™©
`â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€`